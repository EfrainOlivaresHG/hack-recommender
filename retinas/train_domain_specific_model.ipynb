{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 1. Import raw text and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating tokens, saved in variable 'tokens'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Take a source of text and create a python list of all the words.\n",
    "The words retain the same sequence and frequence as in original text.\n",
    "INPUT:\n",
    "    data_source, text file, Content will be parsed for sentences. This should be a plain text document\n",
    "\n",
    "OUTPUT:\n",
    "    tokens, list<list>, list of lists containing a one to one mapping of all the words in the provided text.\n",
    "\"\"\"\n",
    "view_tokens=False\n",
    "data_source = 'data/medical_docs_content.txt'\n",
    "\n",
    "\n",
    "#open input file and tokenize\n",
    "tokens = []\n",
    "with open(data_source, 'r') as source:\n",
    "    for line in source:\n",
    "        line = re.sub(r'\\W', ' ', line) \n",
    "        line_tokens = line.split( )\n",
    "        line_tokens = [token.strip().lower() for token in line_tokens]\n",
    "        tokens.append(line_tokens)\n",
    "\n",
    "if (view_tokens):\n",
    "    for idx in range(2):\n",
    "        print tokens[idx]\n",
    "\n",
    "print \"DONE creating tokens, saved in variable 'tokens'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 2. Create a word2vec model from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model saved to models/medical_docs_content\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Source: Natural Language Processing in Action, Chapter 6\n",
    "Section: 6.5.2 Training domain specific word2vec model\n",
    "INPUT:\n",
    "    tokens, python list, Tokenized data from previous step.\n",
    "    model_path, string, path where we will saved trained model from tokens (depends on last steps data_source)\n",
    "OUTPUT:\n",
    "    model_path, <File on disk> a word2vec trained model from the original tokens.  (hidden weights only)\n",
    "\"\"\"\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model_path  = \"models/{}\".format(re.compile(r'\\..*').sub('', os.path.basename(data_source)))\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    tokens,              # Our array of sentences, each of which is an array of words.\n",
    "    min_count=3,         # Min number of word count to be considered\n",
    "    workers=4,           # Number of threads in parallel. (cores on laptop)\n",
    "    size=300,            # The number of weights in hidden layer, (length of word verctors)\n",
    "    window=6,            # Context window size\n",
    "    sample=1e-3          # subsampling rate for frequent terms\n",
    ")\n",
    "\n",
    "# Save disk space by saving only hidden neurons.  (We lose output weights)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "print \"New model saved to {}\".format(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 3. Import model and test it by looking for similar words.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: ['doctor']\n",
      "Negative: []\n",
      "             0         1\n",
      "0      doctors  0.965073\n",
      "1      assures  0.953188\n",
      "2     protocol  0.952838\n",
      "3     reviewed  0.947542\n",
      "4   concerning  0.944725\n",
      "5        greet  0.944284\n",
      "6  accordingly  0.943018\n",
      "7  medications  0.942222\n",
      "8     messages  0.941312\n",
      "9       advise  0.940864\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load a previously saved word2vec model and use vector math to find words deemed 'similar'\n",
    "\n",
    "INPUT:\n",
    "    model_path: string, path to file containing previously trained set of word2vec vectors.\n",
    "OUTPUT:\n",
    "    positive: list<string>, a list of words to find similar words to.\n",
    "    negavite: list<string>, a list of words whose vectors get subtracted before finding similarity\n",
    "\n",
    "Output is displayed to console.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# INTPUTS:\n",
    "positive = ['doctor']\n",
    "negative = []\n",
    "\n",
    "model = word2vec.Word2Vec.load(model_path)\n",
    "results = model.most_similar(positive=positive, negative=negative, topn=20)\n",
    "# print results\n",
    "data = pd.DataFrame(results)\n",
    "\n",
    "print \"Positive: {}\".format(positive)\n",
    "print \"Negative: {}\".format(negative)\n",
    "print data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 4. Create a 2D map from the vectors in the saved model.  (Retina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 6,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model models/medical_docs_content\n",
      "Saving 2d numpy array from word_vectors to models/vectors_array\n",
      "(6994, 300)\n",
      "Training:\n",
      "sigma: 5 learning_rate: 0.8 train_iterations: 200\n",
      "Saving models/som_weights_3\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This section creates the semantic map from the hidden layer vectors.\n",
    "\t1. Open a pretrained vector set 'data_for_classification_model'\n",
    "\t2. collect all vectors into one single 2d numpy array\n",
    "\t3. pass 2d array to minisom and train a map\n",
    "\t4. Save the map to som_map\n",
    "    \n",
    "INPUTS:\n",
    "    model_path, string, path to file for previously trained model from raw text\n",
    "    vectors_path, string, path to file where only numerical vectors will be saved to pass to minisom\n",
    "    weights_path, string, path to map weights defining the trained 2d minisom\n",
    "    b_collect_new_vectors, boolean, recollect the vector file (if we updated the model)\n",
    "    b_save_new_som_weights, boolean, recalculate and overwrite the weights for the 2d map.\n",
    "    training inputs:\n",
    "    _sigma: float\n",
    "    _learning_rate: float\n",
    "    _train_iterations: int\n",
    "OUTPUT:\n",
    "    Depending on the booleans, the files at vectors_path and weights_path will be overwritten or created.\n",
    "\"\"\"\n",
    "from minisom import MiniSom\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "import numpy as np \n",
    "\n",
    "#INPUTS\n",
    "b_collect_new_vectors = True\n",
    "b_save_new_som_weights = True \n",
    "vectors_path = 'models/vectors_array'\n",
    "weights_path = 'models/som_weights_3'\n",
    "# TRAINING INPUTS\n",
    "_sigma = 5\n",
    "_learning_rate = 0.8\n",
    "_train_iterations = 200\n",
    "#ENDINPUTS\n",
    "\n",
    "\n",
    "print \"Loading model {}\".format(model_path)\n",
    "word_vectors = KeyedVectors.load(model_path)\n",
    "model = word2vec.Word2Vec.load(model_path)\n",
    "\n",
    "if (b_collect_new_vectors):\n",
    "    print \"Saving 2d numpy array from word_vectors to {}\".format(vectors_path)\n",
    "    varrs = np.array([word_vectors[word] for word in word_vectors.wv.vocab.keys()])\n",
    "    np.save(vectors_path, varrs)\n",
    "else:\n",
    "    print \"Loading {}.py word vectors from disk\".format(vectors_path)\n",
    "    varrs = np.load(\"{}.npy\".format(vectors_path))\n",
    "\n",
    "print varrs.shape\n",
    "som = MiniSom(x=128, y=128, input_len=300, sigma=_sigma, learning_rate=_learning_rate)\n",
    "som.random_weights_init(varrs)\n",
    "if (b_save_new_som_weights):\n",
    "    print \"Training:\"\n",
    "    print \"sigma:\", _sigma, \"learning_rate:\", _learning_rate, \"train_iterations:\",_train_iterations\n",
    "    som.train_random(varrs, _train_iterations) # random training\n",
    "\n",
    "    print \"Saving {}\".format(weights_path)\n",
    "    np.save(weights_path, som.weights)\n",
    "\n",
    "\n",
    "            \n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a list of word 'fingerprints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n",
      "13210\n",
      "valuethis\n",
      "valuethis not in vocabulary\n",
      "position\n",
      "[('endeavor', 0.8360309600830078), ('this', 0.8241738080978394), ('funded', 0.8029907941818237), ('requires', 0.7990128993988037), ('exempt', 0.76841139793396)]\n",
      "(71, 123)\n",
      "will\n",
      "[('would', 0.803634762763977), ('considered', 0.7921169996261597), ('successful', 0.7566119432449341), ('candidate', 0.7432190775871277), ('should', 0.7295222282409668)]\n",
      "(95, 47)\n"
     ]
    }
   ],
   "source": [
    "print len(tokens)\n",
    "unique_words = []\n",
    "for line_list in tokens:\n",
    "    for word in line_list:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "\n",
    "print len(unique_words)\n",
    "\n",
    "som.weights = np.load(\"{}.npy\".format(weights_path))\n",
    "\n",
    "\n",
    "stop = 2\n",
    "for word in unique_words:\n",
    "    print word\n",
    "    try:\n",
    "        print model.most_similar(positive=[word], negative=[], topn=5)\n",
    "        print som.winner(word_vectors[word])\n",
    "    except:\n",
    "        print word, \"not in vocabulary\"\n",
    "    stop -= 1\n",
    "    if stop < 0:\n",
    "        break\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating word to location dictionary\n",
      "Number of unique words is 13210\n",
      "Completed,word_to_loc is 6994\n",
      "Completed fingerprints with length 6994\n"
     ]
    }
   ],
   "source": [
    "def generate_word_to_loc(unique_words, word_vectors, som):\n",
    "    print \"Generating word to location dictionary\"\n",
    "    print \"Number of unique words is {}\".format(len(unique_words))\n",
    "    word_to_loc = {}\n",
    "    for word in unique_words:\n",
    "        try:\n",
    "            word_to_loc[word] = som.winner(word_vectors[word])\n",
    "        except:\n",
    "            pass\n",
    "    print \"Completed,word_to_loc is {}\".format(len(word_to_loc))\n",
    "    return word_to_loc\n",
    "\n",
    "word_to_loc = generate_word_to_loc(unique_words, word_vectors, som)\n",
    "\n",
    "def generate_fingerprint_dictionary(word_to_loc, model):\n",
    "    fingerprints = {}\n",
    "    for word, loc in word_to_loc.iteritems():\n",
    "            fingerprints[word] = [loc]\n",
    "            similar_words = model.most_similar(positive=[word], negative=[], topn=20)\n",
    "            [fingerprints[word].append(word_to_loc[tup[0]]) for tup in similar_words] \n",
    "    print \"Completed fingerprints with length {}\".format(len(fingerprints))\n",
    "    return fingerprints\n",
    "\n",
    "fingerprints = generate_fingerprint_dictionary(word_to_loc, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Retina:\n",
    "    def __init__(self, _unique_words, _trained_som, _word_vectors, _model, \n",
    "                 _word_to_loc, _fingerprints):\n",
    "        self.unique_words = _unique_words\n",
    "        self.som = _trained_som\n",
    "        self.word_vectors = _word_vectors\n",
    "        self.model = _model\n",
    "        self.word_to_loc = _word_to_loc\n",
    "        self._fingerprints = _fingerprints\n",
    "\n",
    "         \n",
    "    def location(self, word):\n",
    "        return self.word_to_loc[word]\n",
    "\n",
    "    def fingerprint(self, item):\n",
    "        if type(item) == type('word'):\n",
    "            return self._fingerprints[item]\n",
    "        elif type(item) == type([]):\n",
    "            tups = []\n",
    "            for word in item:\n",
    "                for tup in self.fingerprint(word):\n",
    "                    if tup not in tups:\n",
    "                        tups.append(tup)\n",
    "\n",
    "            return tups\n",
    "            \n",
    "\n",
    "    def fingerprint_x_y(self, word):\n",
    "        xarr = []\n",
    "        yarr = []\n",
    "        for tup in self.fingerprint(word):\n",
    "            xarr.append(tup[0])\n",
    "            yarr.append(tup[1])\n",
    "\n",
    "        return (xarr, yarr)\n",
    "    \n",
    "\n",
    "retina = Retina(unique_words, som, word_vectors, model, word_to_loc, fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location for medical (47, 27)\n",
      "---------\n",
      "Fingerprint for medical [(47, 27), (125, 50), (75, 113), (47, 27), (125, 56), (63, 93), (45, 36), (117, 69), (122, 73), (116, 74), (126, 68), (126, 53), (45, 36), (118, 65), (127, 72), (20, 117), (126, 53), (122, 48), (116, 74), (2, 16), (0, 1)]\n",
      "---------\n",
      "Fingerprint for array medical [(47, 27), (125, 50), (75, 113), (125, 56), (63, 93), (45, 36), (117, 69), (122, 73), (116, 74), (126, 68), (126, 53), (118, 65), (127, 72), (20, 117), (122, 48), (2, 16), (0, 1)]\n",
      "---------\n",
      "XY Fingerprint for medical ([47, 125, 75, 47, 125, 63, 45, 117, 122, 116, 126, 126, 45, 118, 127, 20, 126, 122, 116, 2, 0], [27, 50, 113, 27, 56, 93, 36, 69, 73, 74, 68, 53, 36, 65, 72, 117, 53, 48, 74, 16, 1])\n",
      "---------\n",
      "XY Fingerprint for array medical ([47, 125, 75, 125, 63, 45, 117, 122, 116, 126, 126, 118, 127, 20, 122, 2, 0], [27, 50, 113, 56, 93, 36, 69, 73, 74, 68, 53, 65, 72, 117, 48, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "print \"Location for medical\", retina.location('medical')\n",
    "print \"---------\"\n",
    "print \"Fingerprint for medical\", retina.fingerprint('medical')\n",
    "print \"---------\"\n",
    "print \"Fingerprint for array medical\", retina.fingerprint(['medical'])\n",
    "print \"---------\"\n",
    "print \"XY Fingerprint for medical\", retina.fingerprint_x_y('medical')\n",
    "print \"---------\"\n",
    "print \"XY Fingerprint for array medical\", retina.fingerprint_x_y(['medical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1\n",
      "0  medications  0.960735\n",
      "1      doctors  0.960277\n",
      "2     payments  0.957949\n",
      "3        tests  0.957736\n",
      "4    evaluated  0.956294\n",
      "[40, 60, 14, 15, 57, 32, 53, 14, 56, 42, 60, 61, 12, 45, 11, 11, 44, 31]\n",
      "[110, 54, 82, 82, 62, 113, 64, 79, 59, 106, 57, 55, 82, 58, 85, 81, 60, 91]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAMoCAYAAADsmC4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11efaead0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "wrd = ['interacting']\n",
    "\n",
    "print pd.DataFrame(model.most_similar(positive=wrd, negative=[], topn=20)).head()\n",
    "\n",
    "arrx, arry = retina.fingerprint_x_y(wrd)\n",
    "print arrx\n",
    "print arry\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(arrx,arry)\n",
    "plt.axis([0,128,0,128])\n",
    "plt.grid()\n",
    "plt.title(\"unique_id: {}\".format(wrd))\n",
    "#plt.savefig(\"fingerprints/{}.png\".format(unique_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
