{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data gathering\n",
    "From url_filter data extraction process\n",
    "1. Downloaded html content for staffing and consulting urls\n",
    "2. Downloaded good manual urls content to file as well\n",
    "3. Create a tsv (url, cleaned content, binary) (THIS IS OUR ONE DOC PER LINE FILE)\n",
    "4. Use get_raw_data_good_bad.py script to get one large pool of just the text. (THIS IS OUR CORPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 1. Import raw text and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating tokens, saved in variable 'tokens'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Take a source of text and create a python list of all the words.\n",
    "The words retain the same sequence and frequence as in original text.\n",
    "INPUT:\n",
    "    data_source, text file, Content will be parsed for sentences. This should be a plain text document\n",
    "\n",
    "OUTPUT:\n",
    "    tokens, list<list>, list of lists containing a one to one mapping of all the words in the provided text.\n",
    "\"\"\"\n",
    "view_tokens=False\n",
    "data_source = 'data/content_good_bad.txt'\n",
    "\n",
    "\n",
    "#open input file and tokenize\n",
    "tokens = []\n",
    "with open(data_source, 'r') as source:\n",
    "    for line in source:\n",
    "        line = re.sub(r'\\W', ' ', line) \n",
    "        line_tokens = line.split( )\n",
    "        line_tokens = [token.strip().lower() for token in line_tokens]\n",
    "        tokens.append(line_tokens)\n",
    "\n",
    "if (view_tokens):\n",
    "    for idx in range(2):\n",
    "        print tokens[idx]\n",
    "\n",
    "print \"DONE creating tokens, saved in variable 'tokens'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 2. Create a word2vec model from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model saved to models/content_good_bad\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Source: Natural Language Processing in Action, Chapter 6\n",
    "Section: 6.5.2 Training domain specific word2vec model\n",
    "INPUT:\n",
    "    tokens, python list, Tokenized data from previous step.\n",
    "    model_path, string, path where we will saved trained model from tokens (depends on last steps data_source)\n",
    "OUTPUT:\n",
    "    model_path, <File on disk> a word2vec trained model from the original tokens.  (hidden weights only)\n",
    "\"\"\"\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model_path  = \"models/{}\".format(re.compile(r'\\..*').sub('', os.path.basename(data_source)))\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    tokens,              # Our array of sentences, each of which is an array of words.\n",
    "    min_count=3,         # Min number of word count to be considered\n",
    "    workers=4,           # Number of threads in parallel. (cores on laptop)\n",
    "    size=300,            # The number of weights in hidden layer, (length of word verctors)\n",
    "    window=6,            # Context window size\n",
    "    sample=1e-3          # subsampling rate for frequent terms\n",
    ")\n",
    "\n",
    "# Save disk space by saving only hidden neurons.  (We lose output weights)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "print \"New model saved to {}\".format(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 3. Import model and test it by looking for similar words.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: ['contenu']\n",
      "Negative: []\n",
      "              0         1\n",
      "0        accder  0.892432\n",
      "1        fermer  0.850978\n",
      "2        marque  0.848026\n",
      "3     bienvenue  0.846151\n",
      "4      allemand  0.845688\n",
      "5       logware  0.844236\n",
      "6     utilisant  0.843659\n",
      "7       anglais  0.843402\n",
      "8           cur  0.843356\n",
      "9      logiciel  0.840776\n",
      "10  prsentation  0.839189\n",
      "11      cabinet  0.838785\n",
      "12  dexcellence  0.838694\n",
      "13     institut  0.838617\n",
      "14       passez  0.834564\n",
      "15  rfrencement  0.833111\n",
      "16        titre  0.831944\n",
      "17   rechercher  0.830519\n",
      "18   partenaire  0.830139\n",
      "19     annonces  0.829627\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load a previously saved word2vec model and use vector math to find words deemed 'similar'\n",
    "\n",
    "INPUT:\n",
    "    model_path: string, path to file containing previously trained set of word2vec vectors.\n",
    "OUTPUT:\n",
    "    positive: list<string>, a list of words to find similar words to.\n",
    "    negavite: list<string>, a list of words whose vectors get subtracted before finding similarity\n",
    "\n",
    "Output is displayed to console.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# INTPUTS: aws, doctor, contenu, \n",
    "positive = ['contenu']\n",
    "negative = []\n",
    "\n",
    "model = word2vec.Word2Vec.load(model_path)\n",
    "results = model.most_similar(positive=positive, negative=negative, topn=20)\n",
    "# print results\n",
    "data = pd.DataFrame(results)\n",
    "\n",
    "print \"Positive: {}\".format(positive)\n",
    "print \"Negative: {}\".format(negative)\n",
    "print data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 4. Create a 2D map from the vectors in the saved model.  (Retina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 6,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model models/content_good_bad\n",
      "Loading models/vectors_array.py word vectors from disk\n",
      "(79003, 300)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This section creates the semantic map from the hidden layer vectors.\n",
    "\t1. Open a pretrained vector set 'data_for_classification_model'\n",
    "\t2. collect all vectors into one single 2d numpy array\n",
    "\t3. pass 2d array to minisom and train a map\n",
    "\t4. Save the map to som_map\n",
    "    \n",
    "INPUTS:\n",
    "    model_path, string, path to file for previously trained model from raw text\n",
    "    vectors_path, string, path to file where only numerical vectors will be saved to pass to minisom\n",
    "    weights_path, string, path to map weights defining the trained 2d minisom\n",
    "    b_collect_new_vectors, boolean, recollect the vector file (if we updated the model)\n",
    "    b_save_new_som_weights, boolean, recalculate and overwrite the weights for the 2d map.\n",
    "    training inputs:\n",
    "    _sigma: float\n",
    "    _learning_rate: float\n",
    "    _train_iterations: int\n",
    "OUTPUT:\n",
    "    Depending on the booleans, the files at vectors_path and weights_path will be overwritten or created.\n",
    "\"\"\"\n",
    "from minisom import MiniSom\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "import numpy as np \n",
    "\n",
    "#INPUTS\n",
    "b_collect_new_vectors = False\n",
    "b_save_new_som_weights = False \n",
    "vectors_path = 'models/vectors_array'\n",
    "weights_path = 'models/som_weights_3'\n",
    "# TRAINING INPUTS\n",
    "_sigma = 5\n",
    "_learning_rate = 0.8\n",
    "_train_iterations = 200\n",
    "#ENDINPUTS\n",
    "\n",
    "\n",
    "print \"Loading model {}\".format(model_path)\n",
    "word_vectors = KeyedVectors.load(model_path)\n",
    "model = word2vec.Word2Vec.load(model_path)\n",
    "\n",
    "if (b_collect_new_vectors):\n",
    "    print \"Saving 2d numpy array from word_vectors to {}\".format(vectors_path)\n",
    "    varrs = np.array([word_vectors[word] for word in word_vectors.wv.vocab.keys()])\n",
    "    np.save(vectors_path, varrs)\n",
    "else:\n",
    "    print \"Loading {}.py word vectors from disk\".format(vectors_path)\n",
    "    varrs = np.load(\"{}.npy\".format(vectors_path))\n",
    "\n",
    "print varrs.shape\n",
    "som = MiniSom(x=128, y=128, input_len=300, sigma=_sigma, learning_rate=_learning_rate)\n",
    "som.random_weights_init(varrs)\n",
    "if (b_save_new_som_weights):\n",
    "    print \"Training:\"\n",
    "    print \"sigma:\", _sigma, \"learning_rate:\", _learning_rate, \"train_iterations:\",_train_iterations\n",
    "    som.train_random(varrs, _train_iterations) # random training\n",
    "\n",
    "    print \"Saving {}\".format(weights_path)\n",
    "    np.save(weights_path, som.weights)\n",
    "\n",
    "\n",
    "            \n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a list of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words in vocabulary is 79003\n"
     ]
    }
   ],
   "source": [
    "# print \"Length of all tokens is \", len(tokens)\n",
    "# unique_words = []\n",
    "\n",
    "# recompile = True\n",
    "\n",
    "# if recompile:\n",
    "#     print \"Regenerating unique word list\"\n",
    "#     with open('models/unique_words.txt','w') as target:\n",
    "#         for line_list in tokens:\n",
    "#             for word in line_list:\n",
    "#                 if word not in unique_words:\n",
    "#                     unique_words.append(word)\n",
    "#                     target.write(\"{}\\n\".format(word))\n",
    "    \n",
    "# else:\n",
    "#     print \"Reading saved unique word list\"\n",
    "#     with open('models/unique_words.txt', 'r') as source:\n",
    "#         for word in source.readlines():\n",
    "#             unique_words.append(word.strip())\n",
    "    \n",
    "# print \"unique words in vocab is {}\".format(len(unique_words))\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load(model_path)\n",
    "unique_words = word_vectors.wv.vocab.keys()\n",
    "print \"Length of words in vocabulary is\", len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate a word to location lookup list and fingerprint list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word to location dictionary\n",
      "Number of words is 79003\n",
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def generate_word_to_loc(unique_words, word_vectors, som):\n",
    "    print \"Generating word to location dictionary\"\n",
    "    print \"Number of words is {}\".format(len(unique_words))\n",
    "    word_to_loc = {}\n",
    "    idx = 0\n",
    "    for word in unique_words:\n",
    "        if (idx % 10000==0):\n",
    "            print idx\n",
    "        try:\n",
    "            word_to_loc[word] = som.winner(word_vectors[word])\n",
    "        except:\n",
    "            pass\n",
    "        idx += 1\n",
    "    print \"Completed,word_to_loc is {}\".format(len(word_to_loc))\n",
    "    return word_to_loc\n",
    "\n",
    "word_to_loc = generate_word_to_loc(unique_words, word_vectors, som)\n",
    "\n",
    "def generate_fingerprint_dictionary(word_to_loc, model):\n",
    "    fingerprints = {}\n",
    "    for word, loc in word_to_loc.iteritems():\n",
    "            fingerprints[word] = [loc]\n",
    "            similar_words = model.most_similar(positive=[word], negative=[], topn=20)\n",
    "            [fingerprints[word].append(word_to_loc[tup[0]]) for tup in similar_words] \n",
    "    print \"Completed fingerprints with length {}\".format(len(fingerprints))\n",
    "    return fingerprints\n",
    "\n",
    "regenerate = True\n",
    "if regenerate:\n",
    "    fingerprints = generate_fingerprint_dictionary(word_to_loc, model)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Retina:\n",
    "    def __init__(self, _unique_words, _trained_som, _word_vectors, _model):\n",
    "        self.unique_words = _unique_words\n",
    "        self.som = _trained_som\n",
    "        self.word_vectors = _word_vectors\n",
    "        self.model = _model\n",
    "        #self.word_to_loc = _word_to_loc\n",
    "        #self._fingerprints = _fingerprints\n",
    "\n",
    "         \n",
    "    def location(self, word):\n",
    "        #return self.word_to_loc[word]\n",
    "        return self.som.winner(self.word_vectors[word])\n",
    "\n",
    "    def fingerprint(self, item):\n",
    "        if type(item) == type('word'):\n",
    "            fingerprint = [self.location(item)]\n",
    "            similar_words = self.model.most_similar(positive=[item], negative=[], topn=20)\n",
    "            [fingerprint.append(self.location(tup[0])) for tup in similar_words]\n",
    "            return fingerprint\n",
    "            #return self._fingerprints[item]\n",
    "        elif type(item) == type([]):\n",
    "            tups = []\n",
    "            for word in item:\n",
    "                for tup in self.fingerprint(word):\n",
    "                    if tup not in tups:\n",
    "                        tups.append(tup)\n",
    "\n",
    "            return tups\n",
    "            \n",
    "\n",
    "    def fingerprint_x_y(self, word):\n",
    "        xarr = []\n",
    "        yarr = []\n",
    "        for tup in self.fingerprint(word):\n",
    "            xarr.append(tup[0])\n",
    "            yarr.append(tup[1])\n",
    "\n",
    "        return (xarr, yarr)\n",
    "    \n",
    "\n",
    "retina = Retina(unique_words, som, word_vectors, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location for medical (16, 10)\n",
      "---------\n",
      "Fingerprint for medical [(16, 10), (93, 80), (16, 10), (70, 26), (93, 80), (93, 80), (70, 26), (93, 80), (70, 26), (89, 85), (70, 26), (70, 26), (16, 10), (94, 88), (70, 125), (93, 80), (70, 26), (41, 117), (94, 88), (41, 117), (11, 53)]\n",
      "---------\n",
      "Fingerprint for array medical [(16, 10), (93, 80), (70, 26), (89, 85), (94, 88), (70, 125), (41, 117), (11, 53)]\n",
      "---------\n",
      "XY Fingerprint for medical ([16, 93, 16, 70, 93, 93, 70, 93, 70, 89, 70, 70, 16, 94, 70, 93, 70, 41, 94, 41, 11], [10, 80, 10, 26, 80, 80, 26, 80, 26, 85, 26, 26, 10, 88, 125, 80, 26, 117, 88, 117, 53])\n",
      "---------\n",
      "XY Fingerprint for array medical ([16, 93, 70, 89, 94, 70, 41, 11], [10, 80, 26, 85, 88, 125, 117, 53])\n"
     ]
    }
   ],
   "source": [
    "print \"Location for medical\", retina.location('medical')\n",
    "print \"---------\"\n",
    "print \"Fingerprint for medical\", retina.fingerprint('medical')\n",
    "print \"---------\"\n",
    "print \"Fingerprint for array medical\", retina.fingerprint(['medical'])\n",
    "print \"---------\"\n",
    "print \"XY Fingerprint for medical\", retina.fingerprint_x_y('medical')\n",
    "print \"---------\"\n",
    "print \"XY Fingerprint for array medical\", retina.fingerprint_x_y(['medical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1\n",
      "0          dealt  0.794181\n",
      "1        dealing  0.781541\n",
      "2  communicating  0.763329\n",
      "3  collaborating  0.741985\n",
      "4        merging  0.739591\n",
      "[116, 64, 13, 20, 96, 10, 41, 97, 39, 0, 100, 2, 48, 24, 110, 73, 93, 118]\n",
      "[77, 15, 64, 125, 52, 85, 98, 100, 32, 86, 56, 1, 71, 14, 31, 77, 21, 89]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAMoCAYAAADsmC4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBwAAGBVhBwAAGBVhBwAAGBVPgAXIIAhn1nkyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122ef1510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "wrd = ['interacting']\n",
    "\n",
    "print pd.DataFrame(model.most_similar(positive=wrd, negative=[], topn=20)).head()\n",
    "\n",
    "arrx, arry = retina.fingerprint_x_y(wrd)\n",
    "print arrx\n",
    "print arry\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(arrx,arry)\n",
    "plt.axis([0,128,0,128])\n",
    "plt.grid()\n",
    "plt.title(\"unique_id: {}\".format(wrd))\n",
    "#plt.savefig(\"fingerprints/{}.png\".format(unique_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
